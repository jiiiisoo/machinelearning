{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "지도학습 회귀-모델 선택.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPxFER4Yr80f1VbPzTnJPh6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiiiisoo/machinelearning/blob/main/supervised%20learning_regression_choosing%20model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **모델의 선택**\n",
        "모델 간 비교에도 선형 기저 함수 모델의 M을 결정할 때와 같이 미지의 데이터에 대한 예측 정확도로 평가한다. 즉, holdout 검증과 k-fold 교차검증을 통해 모델의 좋고 나쁨을 평가할 수 있다.\n",
        "\n",
        "모델 A에 LOOCV를 사용하여 앞서 구했던 선형 기저 함수 모델의 LOOCV 결과와 비교하면"
      ],
      "metadata": {
        "id": "qQsvG8OpM3RY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##데이터\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# 나이에 따른 키의 인공 데이터 생성\n",
        "np.random.seed(seed=1)\n",
        "X_min=4 #X의 하한\n",
        "X_max=30 #X의 상한\n",
        "X_n=16 #데이터 개수\n",
        "X=5+25*np.random.rand(X_n) #16명 나이 설정\n",
        "Prm_c=[170, 108, 0.2] #생성 매개 변수\n",
        "T=Prm_c[0]-Prm_c[1]*np.exp(-Prm_c[2]*X)+4*np.random.randn(X_n) #T:출력값\n",
        "np.savez('ch5_data.npz', X=X, X_min=X_min, X_max=X_max, X_n=X_n, T=T)\n",
        "\n",
        "##모델A\n",
        "def model_A(x,w):\n",
        "  y=w[0]-w[1]*np.exp(-w[2]*x)\n",
        "  return y\n",
        "\n",
        "def show_model_A(w):\n",
        "  xb=np.linspace(X_min,X_max,100)\n",
        "  y=model_A(xb,w)\n",
        "  plt.plot(xb,y,c=[.5,.5,.5], lw=4)\n",
        "\n",
        "def mse_model_A(w,x,t):\n",
        "  y=model_A(x,w)\n",
        "  mse=np.mean((y-t)**2)\n",
        "  return mse\n",
        "\n",
        "##최적화\n",
        "from scipy.optimize import minimize\n",
        "def fit_model_A(w_init,x,t):\n",
        "  res1=minimize(mse_model_A,w_init, args=(x,t), method='powell') #첫번째 인수: 최소화할 목표 함수, 두번째: w 초기값, 세번째: 함수 최적화하는 매개 변수 w 이외의 변수, 네번째: 사용할 알고리즘\n",
        "                                                                 # powell 알고리즘: 최소화 함수 사용할 때 늦게 수렴되거나 수렴이 보장되지 않는 경우 실험적으로 사용하는 알고리즘\n",
        "  return res1.x #??"
      ],
      "metadata": {
        "id": "sYnt5-k_OCY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##model A와 비교 위한 선형 기저 함수 모델의 필요한 함수들 가져옴\n",
        "\n",
        "#가우스 함수\n",
        "def gauss(x,mu,s):\n",
        "  return np.exp(-(x-mu)**2/(2*s**2))\n",
        "\n",
        "##선형 기저 함수 모델\n",
        "def gauss_func(w,x):\n",
        "  m=len(w)-1 # w의 개수는 가우스함수 개수보다 하나 많기 때문\n",
        "  mu=np.linspace(5,30,m)\n",
        "  s=mu[1]-mu[0]\n",
        "  y=np.zeros_like(x) #x와 같은 크기로 요소가 0의 행렬 y를 작성\n",
        "  for j in range(m):\n",
        "    y=y+w[j]*gauss(x,mu[j],s)\n",
        "  y=y+w[m]\n",
        "  return y\n",
        "\n",
        "##선형 기저 함수 모델의 mse (평균 제곱 오차)\n",
        "#피팅의 수준 산출\n",
        "def mse_gauss_func(x,t,w):\n",
        "  y=gauss_func(w,x)\n",
        "  mse=np.mean((y-t)**2)\n",
        "  return mse\n",
        "\n",
        "##선형 기저 함수 모델의 해석해 (정확한 값)\n",
        "def fit_gauss_func(x,t,m):\n",
        "  mu=np.linspace(5,30,m)\n",
        "  s=mu[1]-mu[0]\n",
        "  n=x.shape[0]\n",
        "  psi=np.ones((n,m+1)) #항상 1 출력하는 더미함수 (psi_(m+1)=1 만들기 위함)\n",
        "  for j in range (m):\n",
        "    psi[:,j]=gauss(x,mu[j],s)\n",
        "  psi_T=np.transpose(psi)\n",
        "  \n",
        "  a=np.linalg.inv(psi_T.dot(psi))\n",
        "  b=a.dot(psi_T)\n",
        "  w=b.dot(t)\n",
        "  return w\n",
        "\n",
        "##K-fold-cross-validation\n",
        "\n",
        "def Kfold_mse_gauss(x,t,m,k):\n",
        "  n=x.shape[0] #n: x의 데이터 개수\n",
        "  mse_train=np.zeros(k)\n",
        "  mse_test=np.zeros(k)\n",
        "  for i in range(0,k):\n",
        "    x_train=x[np.fmod(range(n),k)!=i] #np.fmod(n,k): n을 k로 나눈 나머지 출력 / n을 range(n)으로 하면 0~n-1까지 각 수를 k로 나눈 나머지 출력됨\n",
        "    t_train=t[np.fmod(range(n),k)!=i]\n",
        "    x_test=x[np.fmod(range(n),k)==i]\n",
        "    t_test=t[np.fmod(range(n),k)==i]\n",
        "    wm=fit_gauss_func(x_train,t_train,m)\n",
        "    mse_train[i]=mse_gauss_func(x_train,t_train,wm)\n",
        "    mse_test[i]=mse_gauss_func(x_test,t_test,wm)\n",
        "  return mse_train,mse_test\n",
        "\n",
        "##main\n",
        "M=range(2,8)\n",
        "K=16 #K의 최대 (K=N이 최대이므로)\n",
        "Cv_Gauss_train=np.zeros((K,len(M)))\n",
        "Cv_Gauss_test=np.zeros((K,len(M)))\n",
        "for i in range (0,len(M)):\n",
        "  Cv_Gauss_train[:,i],Cv_Gauss_test[:,i]=Kfold_mse_gauss(X,T,M[i],K)\n",
        "mean_Gauss_train=np.sqrt(np.mean(Cv_Gauss_train,axis=0)) #axis=0 무슨 의미??\n",
        "mean_Gauss_test=np.sqrt(np.mean(Cv_Gauss_test,axis=0))"
      ],
      "metadata": {
        "id": "Ph1dw5OMQyWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## kfold_modelA\n",
        "def Kfold_model_A(x,t,k):\n",
        "  n=len(x)\n",
        "  mse_train=np.zeros(k)\n",
        "  mse_test=np.zeros(k)\n",
        "  for i in range (0,k):\n",
        "    x_train=x[np.fmod(range(n),k)!=i]\n",
        "    t_train=t[np.fmod(range(n),k)!=i]\n",
        "    x_test=x[np.fmod(range(n),k)==i]\n",
        "    t_test=t[np.fmod(range(n),k)==i]\n",
        "    wm=fit_model_A(np.array([169,113,0.2]),x_train,t_train) #w_init은 사용자 지정\n",
        "    mse_train[i]=mse_model_A(wm,x_train,t_train)\n",
        "    mse_test[i]=mse_model_A(wm,x_test,t_test)\n",
        "  return mse_train, mse_test\n",
        "\n",
        "##main\n",
        "K=16\n",
        "Cv_A_train,Cv_A_test=Kfold_model_A(X,T,K)\n",
        "mean_A_test=np.sqrt(np.mean(Cv_A_test))\n",
        "print('Gauss (M=3) SD={:.2f} cm'.format(mean_Gauss_test[1]))\n",
        "print('Model A SD={:.2f} cm'.format(mean_A_test))\n",
        "SD=np.append(mean_Gauss_test[0:5],mean_A_test)\n",
        "M=range(6)\n",
        "label=['M=2','M=3','M=4','M=5','M=6','Model A']\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.bar(M,SD,tick_label=label, align='center',facecolor='cornflowerblue')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Ai-GKc3yOPDK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "c92756bf-24d3-4968-8cf3-c9574085fc2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gauss (M=3) SD=6.51 cm\n",
            "Model A SD=4.72 cm\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOOCV로 선형 기저 함수에서 M:2~6일 경우와 model A의 오차 SD를 비교해보면 model A가 M=3일 때보다 작은 것으로 보아 model A가 데이터에 더 적합함을 볼 수 있다."
      ],
      "metadata": {
        "id": "QEtJ4PESKlQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **정리**\n",
        "\n",
        "어느 데이터든 알맞은 함수와 모델을 찾으려면\n",
        "\n",
        "1. 입력 변수와 목표 변수의 데이터를 둔다.\n",
        "\n",
        "2. 무엇을 가지고 예측의 정확도를 높일지 목적 함수를 결정한다. (지금까지는 평균 제곱 오차로 결정했음)\n",
        "\n",
        "3. 모델의 후보를 결정한다. (선형 회귀 모델, 곡선 모델, 데이터의 특성 반영한 모델 등등)\n",
        "\n",
        "4. 검증을 통해 최적의 매개 변수를 결정한다. (holdout 검증을 이용한다면 test data, training data를 나누어 training data로 목적 함수가 최대 또는 최소가 되도록 변수(w)를 결정한다.)\n",
        "\n",
        "5. test data의 입력변수 를 각 모델에 대입하여 test data를 예측하여 오차가 적은 모델을 선택한다.\n",
        "\n",
        "6. 모델이 결정되면 보유한 데이터를 모두 사용하여 최적의 모델의 매개 변수를 최적화한다.\n"
      ],
      "metadata": {
        "id": "Q8eLLpYLK4pc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "출처: 파이썬으로 배우는 머신러닝의 교과서-이시카와아키히코"
      ],
      "metadata": {
        "id": "pvzK2bnxPzpf"
      }
    }
  ]
}